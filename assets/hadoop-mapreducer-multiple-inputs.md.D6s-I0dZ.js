import{_ as a,c as r,o,ae as t}from"./chunks/framework.BR0IJ75L.js";const s=JSON.parse('{"title":"hadoop mapreducer 多输入配置","description":"","frontmatter":{"title":"hadoop mapreducer 多输入配置","date":"2018-08-23T00:00:00.000Z"},"headers":[],"relativePath":"hadoop-mapreducer-multiple-inputs.md","filePath":"hadoop-mapreducer-multiple-inputs.md"}'),d={name:"hadoop-mapreducer-multiple-inputs.md"};function p(i,e,l,c,u,h){return o(),r("div",null,[...e[0]||(e[0]=[t('<h1 id="hadoop-mapreducer-多输入配置" tabindex="-1">hadoop mapreducer 多输入配置 <a class="header-anchor" href="#hadoop-mapreducer-多输入配置" aria-label="Permalink to &quot;hadoop mapreducer 多输入配置&quot;">​</a></h1><h2 id="为什么需要多输入" tabindex="-1">为什么需要多输入 <a class="header-anchor" href="#为什么需要多输入" aria-label="Permalink to &quot;为什么需要多输入&quot;">​</a></h2><p>使用MapReduce的时候经常需要加载词典或者配置数据</p><h2 id="mapreduce文件分发配置参数" tabindex="-1">MapReduce文件分发配置参数 <a class="header-anchor" href="#mapreduce文件分发配置参数" aria-label="Permalink to &quot;MapReduce文件分发配置参数&quot;">​</a></h2><ol><li>-file 将客户端本地文件上传到HDFS然后分发到计算节点</li><li>-cachefile 将HDFS文件分发到计算节点</li><li>-cacheArchive 将HDFS压缩文件分发到计算节点并解压，也可以指定符号链接</li><li>-files 将指定的本地/HDFS文件分发到各个task的工作目录下，部队文件进行任何处理</li></ol>',5)])])}const m=a(d,[["render",p]]);export{s as __pageData,m as default};
